{% extends "base.html" %}

{% block title %}Home - LearnFlow AI{% endblock %}

{% block content %}
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
<style>
   body {
      background: linear-gradient(135deg, #101725, #0a0e16);
      font-family: 'Inter', sans-serif;
      color: #e5e7eb;
      margin: 0;
   }

  .chat-container-card {
    max-width: 100%;
    width: clamp(300px, 90%, 1200px);
    margin: 2rem auto;
    padding: 1.5rem;
    background-color: #1f2937;
    border-radius: 1.5rem;
    box-shadow: 0 12px 40px rgba(0, 0, 0, 0.6);
    border: 1px solid #374151;
    overflow: hidden;
    transition: transform 0.4s ease, box-shadow 0.4s ease;
}

.chat-container-card:hover {
    transform: translateY(-4px);
    box-shadow: 0 16px 50px rgba(0, 0, 0, 0.7);
}


/* Header styling: Glassmorphism Effect */
.chat-header {
    /* Background must be slightly transparent with a blur */
    background: rgba(255, 255, 255, 0.1); 
    /* The key to glassmorphism */
    backdrop-filter: blur(10px); 
    -webkit-backdrop-filter: blur(10px); /* For Safari support */
    
    padding: 2.5rem 1.5rem; 
    border-radius: 12px; /* Rounded corners */
    border: 1px solid rgba(255, 255, 255, 0.18); /* Light border */
    box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.37); /* Stronger, transparent shadow */
    text-align: center;
}

.chat-header h1 {
    font-size: 3rem;
    font-weight: 700;
    /* Text color for glassmorphism often has a slight shadow or transparency */
    color: #ffffff; 
    text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.5); 
    letter-spacing: -0.04em;
    line-height: 1.1;
}

.chat-header p {
    font-size: 1.125rem;
    color: #f3f4f6; /* Very light color */
    margin-top: 0.5rem;
    max-width: 32rem;
    margin-left: auto;
    margin-right: auto;
}

/* Main chat area layout */
.chat-area {
    display: flex;
    flex-direction: column; /* Stacks on small screens */
    padding: 0; 
    gap: 0;
    /* On mobile, allow the chat area to use most of the screen */
    min-height: calc(100vh - 5rem); 
    max-height: 100vh;
}

/* Chat log container - Message feed */
#chatLog {
    flex-grow: 1;
    overflow-y: auto;
    padding: 1.5rem; 
    background-color: #0f172a; /* Very dark background for log */
    border: none;
    border-radius: 0;
    transition: background-color 0.3s ease-in-out;
    /* Removed min/max height properties to rely on flex-grow */
}

/* Message styling */
.chat-message {
    display: flex;
    align-items: flex-start;
    margin-bottom: 1rem;
    padding: 0.75rem 1rem;
    /* More distinct, modern rounded corners */
    border-radius: 1.25rem 0.5rem 1.25rem 0.5rem; 
    white-space: pre-wrap;
    word-wrap: break-word;
    max-width: 85%; /* Reduced max-width for better appearance */
    line-height: 1.5;
    font-size: 1rem;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2); /* Subtle shadow for depth */
}

.chat-message strong { font-weight: 700; margin-right: 0.5rem; min-width: fit-content; }

/* User message: brighter blue, distinct corner shape */
.chat-message.user { 
    justify-content: flex-end; 
    align-self: flex-end; 
    background-color: #6366f1; /* Brighter, more primary color */
    color: #ffffff; 
    border-radius: 1.25rem 0.5rem 0.5rem 1.25rem; /* Pointed top right */
}

/* AI message: darker background, distinct corner shape, slight border */
.chat-message.ai { 
    justify-content: flex-start; 
    align-self: flex-start; 
    background-color: #1f2937; 
    color: #e5e7eb; 
    border-radius: 0.5rem 1.25rem 1.25rem 0.5rem; /* Pointed top left */
    border: 1px solid #334155; 
}

.chat-message.error { background-color: #b91c1c; color: #ffffff; border: 1px solid #dc2626; }

/* Input and button area (Mobile - bottom dock) */
.chat-input-area {
    display: flex;
    flex-direction: column;
    gap: 1rem;
    padding: 1.5rem;
    border-top: 1px solid #374151;
    background-color: #1a2434; /* Slightly lighter dark color for contrast */
}

/* Combined Text and Voice Input Container */
.combined-input-container {
    display: flex;
    gap: 0.75rem;
    align-items: center;
    width: 100%;
}

/* Text Input Styling */
#chatInput {
    flex-grow: 1;
    padding: 0.75rem 1.25rem;
    border-radius: 1rem; /* Softened corners */
    background-color: #111827; /* Very dark input field */
    color: #e5e7eb;
    border: 1px solid #334155; /* Refined border color */
    transition: border-color 0.3s, box-shadow 0.3s;
    outline: none;
    font-size: 1rem;
    display: block !important; 
}
#chatInput:focus { 
    border-color: #818cf8; 
    box-shadow: 0 0 0 2px rgba(99, 102, 241, 0.5); /* Focus ring */
}

/* Send Button Styling */
.action-button.send {
    display: flex !important; 
    align-items: center;
    justify-content: center;
    padding: 0.75rem; /* Square padding */
    border-radius: 1rem; /* Matched input field radius */
    background-color: #6366f1; /* Matched user message color */
    color: #fff;
    font-weight: 600;
    border: none;
    cursor: pointer;
    transition: background-color 0.3s, transform 0.1s;
    flex-shrink: 0;
    width: 3.5rem; 
    height: 3.5rem;
}
.action-button.send:hover { background-color: #4f46e5; transform: translateY(-1px); }


/* Voice Input Styling (Retained for visual consistency) */
.voice-input-container {
    display: flex;
    gap: 1rem;
    align-items: center;
    width: 100%;
    padding: 0.5rem 0; 
}

#recordButton {
    /* ... (mostly kept the same, added shadow) ... */
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    /* ... */
}
/* ... (recordButton hover, recording, disabled, and pulse are kept) ... */

#voiceStatus {
    flex-grow: 1;
    color: #94a3b8; /* Slightly lighter status text */
    font-style: italic;
    padding: 0.5rem 0;
}

/* Button Group Styling (Mobile - horizontal wrap) */
.button-group {
    display: flex;
    flex-wrap: wrap;
    gap: 0.75rem;
    justify-content: center;
    padding-top: 0.5rem;
}

.action-button {
    flex: 1 1 150px; 
    padding: 0.75rem 1.25rem; /* Standardized button padding */
    border-radius: 0.75rem; /* Slightly softer radius for utility buttons */
    font-weight: 600;
    text-align: center;
    transition: all 0.3s ease-in-out;
    box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
    cursor: pointer;
    border: none;
}

/* NEW: Stop Speaking Button (kept original colors) */
.action-button.stop-speak { 
    background-color: #f59e0b; 
    color: #1f2937; 
    display: none; 
    order: -1; 
}
.action-button.stop-speak:hover { background-color: #d97706; transform: translateY(-2px); }

/* Other buttons (kept original colors, standardized hover effects) */
.action-button.summarize { background-color: #10b981; color: #fff; }
.action-button.summarize:hover { background-color: #059669; transform: translateY(-2px); }

.action-button.export { background-color: #3b82f6; color: #fff; }
.action-button.export:hover { background-color: #2563eb; transform: translateY(-2px); }

.action-button.clear { background-color: #ef4444; color: #fff; }
.action-button.clear:hover { background-color: #dc2626; transform: translateY(-2px); }

/* Responsive adjustments for large screens (md: 768px and up) */
@media (min-width: 768px) {
    /* Assuming a parent container of chat-container-card */
    .chat-container-card { max-width: 90%; height: 90vh; } 
    .chat-area { 
        flex-direction: row; 
        min-height: 100%; /* Fill the height of the container card */
    }
    
    /* Log on the left (65%) */
    #chatLog { 
        width: 65%; 
        min-height: 100%; 
        max-height: 100%; 
        border-radius: 0 0 0 1.5rem; 
        padding: 2rem; /* Increased padding on desktop */
        background-color: #0f172a; 
    }
    
    /* Utilities/Input on the right (35%) */
    .chat-input-area { 
        width: 35%; 
        border-top: none; 
        border-left: 1px solid #334155; /* Subtle border change */
        border-radius: 0 0 1.5rem 0; 
        flex-direction: column; 
        justify-content: flex-start;
        background-color: #111827; /* Slightly darker than log for contrast */
        padding: 2rem;
    }
    
    /* Button group becomes a vertical list of utilities */
    .button-group { 
        flex-direction: column; 
        gap: 1rem; 
        width: 100%;
        padding-top: 1rem;
    }
    .action-button { 
        flex: none; 
        width: 100%; 
        height: auto;
    }
    .action-button.stop-speak { flex: none; width: 100%; }
    
    /* Combined text/mic input remains horizontal */
    .combined-input-container {
        flex-direction: row; 
        height: 3.5rem; 
    }
    .action-button.send {
        width: 3.5rem; /* Force square */
        height: 3.5rem;
        padding: 0; 
        border-radius: 1rem;
    }
}

/* Loader styling (kept the same) */
.loader { width: 32px; height: 32px; border: 4px solid #4f46e5; border-top-color: transparent; border-radius: 50%; animation: spin 1s linear infinite; margin: 1.5rem auto; }
@keyframes spin { to { transform: rotate(360deg); } }

</style>

<div class="chat-container-card">
Â  Â  <div class="chat-header">
Â  Â  Â  Â  <h1 class="text-4xl sm:text-5xl font-extrabold text-white tracking-tight">
Â  Â  Â  Â  Â  Â  Welcome, {{ user.username }} <span class="wave-emoji inline-block">ğŸ‘‹</span>
Â  Â  Â  Â  </h1>
Â  Â  Â  Â  <p class="text-base sm:text-lg text-gray-400 font-light">
Â  Â  Â  Â  Â  Â  Youâ€™ve joined LearnFlow AI, your powerful educational partner. 
Â  Â  Â  Â  </p>
Â  Â  </div>

Â  Â  <div class="chat-area">
Â  Â  Â  Â  <div id="chatLog" class="overflow-y-auto">
Â  Â  Â  Â  Â  Â  </div>

Â  Â  Â  Â  <div class="chat-input-area">
Â  Â  Â  Â  Â  Â  <h2 class="text-2xl font-semibold text-indigo-400 flex items-center gap-2">
Â  Â  Â  Â  Â  Â  Â  Â  <svg class="w-7 h-7 text-indigo-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  xmlns="http://www.w3.org/2000/svg">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.549A9.863 9.863 0 0112 10a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.549A9.863 9.863 0 0112 4c4.97 0 9 3.582 9 8z" />
Â  Â  Â  Â  Â  Â  Â  Â  </svg>
Â  Â  Â  Â  Â  Â  Â  Â  Ask LearnFlow AI 
Â  Â  Â  Â  Â  Â  </h2>
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="combined-input-container">
Â  Â  Â  Â  Â  Â  Â  Â  <input type="text" id="chatInput" placeholder="Type your question..." onkeydown="handleKey(event)">
Â  Â  Â  Â  Â  Â  Â  Â  <button onclick="sendChat()" class="action-button send" id="sendChatButton">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <path stroke-linecap="round" stroke-linejoin="round" d="M13 10V3L4 14h7v7l9-11h-7z" />
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </svg>
Â  Â  Â  Â  Â  Â  Â  Â  </button> 
Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <div class="voice-input-container">
Â  Â  Â  Â  Â  Â  Â  Â  <button id="recordButton" onclick="toggleRecording()" title="Start Recording">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3.9-3.4 7-7.3 7s-7.3-3.1-7.3-7H4c0 4.3 3.3 7.8 7.5 8.3v3.7h1v-3.7c4.2-.5 7.5-4 7.5-8.3h-2.7z"/>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </svg>
Â  Â  Â  Â  Â  Â  Â  Â  </button>
Â  Â  Â  Â  Â  Â  Â  Â  <div id="voiceStatus">Initializing voice service...</div>
Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  <div class="button-group">
Â  Â  Â  Â  Â  Â  Â  Â  <button onclick="stopSpeaking()" class="action-button stop-speak" id="stopSpeakingButton">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <span class="text-xl">ğŸ”‡</span> Stop Speaking
Â  Â  Â  Â  Â  Â  Â  Â  </button>
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  <button onclick="summarizeChat()" class="action-button summarize">Summarize Chat</button>
Â  Â  Â  Â  Â  Â  Â  Â  <button onclick="exportChat()" class="action-button export">Export Chat</button>
Â  Â  Â  Â  Â  Â  Â  Â  <button onclick="clearChat()" class="action-button clear">Clear Chat</button>
Â  Â  Â  Â  Â  Â  </div>
Â  Â  Â  Â  </div>
Â  Â  </div>
</div>

<script>
Â  Â  // Constants and Global Variables
Â  Â  const chatLog = document.getElementById('chatLog');
Â  Â  const stopSpeakingButton = document.getElementById('stopSpeakingButton');
Â  Â  const recordButton = document.getElementById('recordButton');
Â  Â  const voiceStatus = document.getElementById('voiceStatus');
Â  Â  const chatInput = document.getElementById('chatInput'); // New reference

Â  Â  const responseLimit = 3; // Set your limit
Â  Â  const username = "{{ user.username }}";
Â  Â  const chatHistoryKey = `chatHistory-${username}`;
Â  Â  const responseCountKey = `responseCount-${username}`;
Â  Â  let responseCount = localStorage.getItem(responseCountKey) ? parseInt(localStorage.getItem(responseCountKey)) : 0;
Â  Â  
Â  Â  // --- Speech Synthesis Variables (TTS) ---
Â  Â  let voices = [];
Â  Â  let isSpeaking = false; // Tracks if the AI is currently speaking
Â  Â  
Â  Â  // --- Speech Recognition Variables (STT) ---
Â  Â  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
Â  Â  let recognition = null;
Â  Â  let isRecording = false; // Tracks if the microphone is actively listening

Â  Â  // --- API Configuration ---
Â  Â  // NOTE: REPLACE THIS PLACEHOLDER WITH YOUR ACTUAL GEMINI API KEY!
Â  Â  const apiKey = "AIzaSyBo-nakWm_HBUBStldTAKzcAdvB4OU46HU"; 
Â  Â  const modelName = 'gemini-2.5-flash'; 
Â  Â  const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/${modelName}:generateContent?key=${apiKey}`;

Â  Â  // Helper to extract a clean text message from a chat message div
Â  Â  function extractText(child, prefix) {
Â  Â  Â  Â  // Find the text content, and remove the prefix and any strong tags
Â  Â  Â  Â  let text = child.textContent.trim();
Â  Â  Â  Â  // More robust prefix removal for the history extraction
Â  Â  Â  Â  if (text.startsWith(prefix)) {
Â  Â  Â  Â  Â  Â  text = text.substring(prefix.length).trim();
Â  Â  Â  Â  }
Â  Â  Â  Â  // Ensure any strong tag content is removed if not done above
Â  Â  Â  Â  if (child.querySelector('strong')) {
Â  Â  Â  Â  Â  Â  text = text.replace(child.querySelector('strong').textContent, '').trim();
Â  Â  Â  Â  }
Â  Â  Â  Â  return text;
Â  Â  }

Â  Â  // ## TTS Functions (Text-to-Speech) ##
Â  Â  
Â  Â  function populateVoices() {
Â  Â  Â  Â  voices = speechSynthesis.getVoices();
Â  Â  }
Â  Â  
Â  Â  populateVoices();
Â  Â  if (speechSynthesis.onvoiceschanged !== undefined) {
Â  Â  Â  Â  speechSynthesis.onvoiceschanged = populateVoices;
Â  Â  }

Â  Â  function speakText(text) {
Â  Â  Â  Â  if (!('speechSynthesis' in window)) {
Â  Â  Â  Â  Â  Â  // Do not speak if not supported
Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  }

Â  Â  Â  Â  stopSpeaking(); // Stop any current speech before starting a new one

Â  Â  Â  Â  isSpeaking = true;
Â  Â  Â  Â  stopSpeakingButton.style.display = 'block'; 

Â  Â  Â  Â  const utterance = new SpeechSynthesisUtterance(text);
Â  Â  Â  Â  
Â  Â  Â  Â  // Attempt to find a preferred voice
Â  Â  Â  Â  const preferredVoices = [
Â  Â  Â  Â  Â  Â  "Google US English", "Microsoft Zira", "Daniel", "Samantha", "Ting-Ting"
Â  Â  Â  Â  ];

Â  Â  Â  Â  let selectedVoice = null;
Â  Â  Â  Â  for (let name of preferredVoices) {
Â  Â  Â  Â  Â  Â  selectedVoice = voices.find(voice => voice.name.includes(name));
Â  Â  Â  Â  Â  Â  if (selectedVoice) break;
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  // Fallback to a generic English voice
Â  Â  Â  Â  if (!selectedVoice) {
Â  Â  Â  Â  Â  Â  selectedVoice = voices.find(voice => voice.lang.includes('en'));
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  if (selectedVoice) {
Â  Â  Â  Â  Â  Â  utterance.voice = selectedVoice;
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  utterance.rate = 1.0; 
Â  Â  Â  Â  utterance.pitch = 1.0; 

Â  Â  Â  Â  utterance.onend = () => {
Â  Â  Â  Â  Â  Â  isSpeaking = false;
Â  Â  Â  Â  Â  Â  stopSpeakingButton.style.display = 'none'; 
Â  Â  Â  Â  Â  Â  // Ready for next input after AI finishes speaking
Â  Â  Â  Â  Â  Â  if (!isRecording) {
Â  Â  Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Tap the microphone to speak...";
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  };
Â  Â  Â  Â  
Â  Â  Â  Â  utterance.onerror = (event) => {
Â  Â  Â  Â  Â  Â  console.error('Speech synthesis error:', event);
Â  Â  Â  Â  Â  Â  isSpeaking = false;
Â  Â  Â  Â  Â  Â  stopSpeakingButton.style.display = 'none';
Â  Â  Â  Â  Â  Â  Â if (!isRecording) {
Â  Â  Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Tap the microphone to speak...";
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  };

Â  Â  Â  Â  speechSynthesis.speak(utterance);
Â  Â  }
Â  Â  
Â  Â  function stopSpeaking() {
Â  Â  Â  Â  if ('speechSynthesis' in window && speechSynthesis.speaking) {
Â  Â  Â  Â  Â  Â  speechSynthesis.cancel();
Â  Â  Â  Â  Â  Â  isSpeaking = false;
Â  Â  Â  Â  Â  Â  stopSpeakingButton.style.display = 'none';
Â  Â  Â  Â  Â  Â  // Update status only if not currently recording
Â  Â  Â  Â  Â  Â  if (!isRecording) {
Â  Â  Â  Â  Â  Â  Â  Â  Â voiceStatus.textContent = "Tap the microphone to speak...";
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  }

Â  Â  // ## STT Functions (Speech-to-Text) ##

Â  Â  function setupRecognition() {
Â  Â  Â  Â  if (!SpeechRecognition) {
Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Voice input not supported. Use Chrome or Edge.";
Â  Â  Â  Â  Â  Â  recordButton.disabled = true;
Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  recognition = new SpeechRecognition();
Â  Â  Â  Â  recognition.continuous = false; // Get one result per recording
Â  Â  Â  Â  recognition.interimResults = false;
Â  Â  Â  Â  recognition.lang = 'en-US';

Â  Â  Â  Â  recognition.onstart = () => {
Â  Â  Â  Â  Â  Â  isRecording = true;
Â  Â  Â  Â  Â  Â  recordButton.classList.add('recording');
Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Listening... Speak clearly now.";
Â  Â  Â  Â  Â  Â  stopSpeaking(); // Stop AI from talking when user starts speaking
Â  Â  Â  Â  };

Â  Â  Â  Â  recognition.onresult = (event) => {
Â  Â  Â  Â  Â  Â  const last = event.results.length - 1;
Â  Â  Â  Â  Â  Â  const transcript = event.results[last][0].transcript;
Â  Â  Â  Â  Â  Â  console.log("Transcript:", transcript);
Â  Â  Â  Â  Â  Â  // Immediately process the transcription
Â  Â  Â  Â  Â  Â  processVoiceQuery(transcript);
Â  Â  Â  Â  };

Â  Â  Â  Â  recognition.onerror = (event) => {
Â  Â  Â  Â  Â  Â  console.error('Speech recognition error:', event.error);
Â  Â  Â  Â  Â  Â  // Stop recording state
Â  Â  Â  Â  Â  Â  isRecording = false; 
Â  Â  Â  Â  Â  Â  recordButton.classList.remove('recording');
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // Provide specific user feedback
Â  Â  Â  Â  Â  Â  if (event.error === 'not-allowed') {
Â  Â  Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Permission denied. Please enable microphone access.";
Â  Â  Â  Â  Â  Â  } else if (event.error === 'no-speech') {
Â  Â  Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "No speech detected. Tap the microphone to try again.";
Â  Â  Â  Â  Â  Â  } else if (event.error !== 'aborted') {
Â  Â  Â  Â  Â  Â  Â  Â  voiceStatus.textContent = `Error: ${event.error}. Tap the microphone to try again.`;
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  // 'aborted' can happen when recognition.stop() is called manually
Â  Â  Â  Â  Â  Â  Â  Â  Â voiceStatus.textContent = "Tap the microphone to speak...";
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  };
Â  Â  Â  Â  
Â  Â  Â  Â  recognition.onend = () => {
Â  Â  Â  Â  Â  Â  Â // Only reset UI state if a full query process is not ongoing
Â  Â  Â  Â  Â  Â  Â if (isRecording) {
Â  Â  Â  Â  Â  Â  Â  Â  Â recordButton.classList.remove('recording');
Â  Â  Â  Â  Â  Â  Â  Â  Â isRecording = false;
Â  Â  Â  Â  Â  Â  Â  Â  Â // Status will be updated by speakText.onend or the error handler
Â  Â  Â  Â  Â  Â  Â }
Â  Â  Â  Â  };
Â  Â  }
Â  Â  
Â  Â  // Initialize recognition on load
Â  Â  setupRecognition();

Â  Â  function toggleRecording() {
Â  Â  Â  Â  if (!recognition) return; 

Â  Â  Â  Â  if (isRecording) {
Â  Â  Â  Â  Â  Â  // Stop recording if the user taps the button again
Â  Â  Â  Â  Â  Â  recognition.stop();
Â  Â  Â  Â  } else if (isSpeaking) {
Â  Â  Â  Â  Â  Â  Â // If AI is speaking, interrupt it
Â  Â  Â  Â  Â  Â  Â stopSpeaking();
Â  Â  Â  Â  Â  Â  Â voiceStatus.textContent = "Interrupted. Tap to speak...";
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  // Start recording
Â  Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  Â  recognition.start();
Â  Â  Â  Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  Â  Â  Â  // Catch error if recognition.start() is called when already active (shouldn't happen with state check)
Â  Â  Â  Â  Â  Â  Â  Â  Â if (e.name !== 'InvalidStateError') {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â console.error("Recording error:", e);
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â voiceStatus.textContent = "Error starting mic. Check console/permissions.";
Â  Â  Â  Â  Â  Â  Â  Â  Â }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  }
Â  Â  
Â  Â  // Function to handle the transcribed query
Â  Â  function processVoiceQuery(query) {
Â  Â  Â  Â  if (query.trim()) {
Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Sending question to AI...";
Â  Â  Â  Â  Â  Â  sendGeminiQuery(query.trim());
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Empty recording. Tap the microphone to speak...";
Â  Â  Â  Â  }
Â  Â  }


Â  Â  // ## Core Chat/API Functions ##

Â  Â  // Handles Enter key press on the text input
Â  Â  function handleKey(event) {
Â  Â  Â  Â  if (event.key === 'Enter') {
Â  Â  Â  Â  Â  Â  sendChat();
Â  Â  Â  Â  }
Â  Â  }

Â  Â  // Function to handle text input and trigger the query
Â  Â  function sendChat() {
Â  Â  Â  Â  const query = chatInput.value.trim();
Â  Â  Â  Â  if (query) {
Â  Â  Â  Â  Â  Â  if (isRecording) {
Â  Â  Â  Â  Â  Â  Â  Â  recognition.stop(); // Stop voice input if text is sent
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  chatInput.value = ''; // Clear input field
Â  Â  Â  Â  Â  Â  sendGeminiQuery(query);
Â  Â  Â  Â  }
Â  Â  }

Â  Â  // Load chat history from localStorage on page load
Â  Â  document.addEventListener('DOMContentLoaded', () => {
Â  Â  Â  Â  const storedChat = localStorage.getItem(chatHistoryKey);
Â  Â  Â  Â  stopSpeakingButton.style.display = 'none';

Â  Â  Â  Â  if (storedChat) {
Â  Â  Â  Â  Â  Â  chatLog.innerHTML = storedChat;
Â  Â  Â  Â  }
Â  Â  Â  Â  
Â  Â  Â  Â  // Ensure the initial welcome message is present
Â  Â  Â  Â  if (!chatLog.innerHTML.includes("Hello, {{ user.username }}!")) {
Â  Â  Â  Â  Â  Â  Â chatLog.innerHTML = `
Â  Â  Â  Â  Â  Â  Â  Â  Â <div class="chat-message ai">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â <strong>Ai:</strong> 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â <span class="text-gray-400">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Hello, {{ user.username }}! 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â </span>
Â  Â  Â  Â  Â  Â  Â  Â  Â </div>` + chatLog.innerHTML;
Â  Â  Â  Â  } 
Â  Â  Â  Â  
Â  Â  Â  Â  chatLog.scrollTop = chatLog.scrollHeight;
Â  Â  Â  Â  voiceStatus.textContent = recognition ? "Tap the microphone to speak..." : "Voice service unavailable.";
Â  Â  });

Â  Â  function saveChatHistory() {
Â  Â  Â  Â  localStorage.setItem(chatHistoryKey, chatLog.innerHTML);
Â  Â  Â  Â  localStorage.setItem(responseCountKey, responseCount);
Â  Â  }
Â  Â  
Â  Â  // Function to remove markdown formatting (like ** for bolding) from text
Â  Â  function cleanText(text) {
Â  Â  Â  Â  // Remove double asterisks (**) for bolding, asterisks (*) for italics, and new lines
Â  Â  Â  Â  return text.replace(/\*\*/g, '').replace(/\*/g, '').replace(/\n/g, ' ').trim();
Â  Â  }

Â  Â  // Typing animation function - Calls speakText on completion
Â  Â  function typeWriter(element, text, speed = 15) { 
Â  Â  Â  Â  // Apply cleaning right here before display
Â  Â  Â  Â  const cleanedText = cleanText(text); 
Â  Â  Â  Â  
Â  Â  Â  Â  let i = 0;
Â  Â  Â  Â  // Use an empty string for the AI prefix as the strong tag already exists
Â  Â  Â  Â  element.innerHTML = `<strong>Ai:</strong> `; 
Â  Â  Â  Â  const contentSpan = document.createElement('span');
Â  Â  Â  Â  element.appendChild(contentSpan);

Â  Â  Â  Â  function type() {
Â  Â  Â  Â  Â  Â  // Check if the speech was cancelled manually
Â  Â  Â  Â  Â  Â  if (!isSpeaking && i > 0) return; 

Â  Â  Â  Â  Â  Â  if (i < cleanedText.length) {
Â  Â  Â  Â  Â  Â  Â  Â  contentSpan.textContent += cleanedText.charAt(i); 
Â  Â  Â  Â  Â  Â  Â  Â  i++;
Â  Â  Â  Â  Â  Â  Â  Â  setTimeout(type, speed);
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  saveChatHistory();
Â  Â  Â  Â  Â  Â  Â  Â  speakText(cleanedText); // <-- Speak the cleaned text after typing
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  chatLog.scrollTop = chatLog.scrollHeight;
Â  Â  Â  Â  }
Â  Â  Â  Â  type();
Â  Â  }
Â  Â  
Â  Â  // Main function to send the query to Gemini and handle the response
Â  Â  async function sendGeminiQuery(query) {
Â  Â  Â  Â  stopSpeaking(); // Ensure no lingering speech
Â  Â  Â  Â  
Â  Â  Â  Â  // 1. Display user message
Â  Â  Â  Â  const userMsgDiv = document.createElement('div');
Â  Â  Â  Â  userMsgDiv.className = "chat-message user";
Â  Â  Â  Â  userMsgDiv.innerHTML = `<strong>You:</strong> ${query}`;
Â  Â  Â  Â  chatLog.appendChild(userMsgDiv);
Â  Â  Â  Â  chatLog.scrollTop = chatLog.scrollHeight;
Â  Â  Â  Â  saveChatHistory();
Â  Â  Â  Â  
Â  Â  Â  Â  // 2. Rate Limit Check
Â  Â  Â  Â  if (responseCount >= responseLimit) {
Â  Â  Â  Â  Â  Â  const upgradeMsg = `You've reached your free chat limit of ${responseLimit} questions! Please upgrade for unlimited access.`;
Â  Â  Â  Â  Â  Â  const aiMsgDiv = document.createElement('div');
Â  Â  Â  Â  Â  Â  aiMsgDiv.className = "chat-message error"; 
Â  Â  Â  Â  Â  Â  aiMsgDiv.innerHTML = `<strong>Ai:</strong> <span class="text-xl inline-block mr-2">ğŸ”’</span> ${upgradeMsg}`;
Â  Â  Â  Â  Â  Â  chatLog.appendChild(aiMsgDiv);
Â  Â  Â  Â  Â  Â  saveChatHistory();
Â  Â  Â  Â  Â  Â  chatLog.scrollTop = chatLog.scrollHeight;
Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Free limit reached. Clear chat or upgrade.";
Â  Â  Â  Â  Â  Â  speakText(upgradeMsg); // Speak the error message
Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  }

Â  Â  Â  Â  // 3. Display Loader
Â  Â  Â  Â  const loaderDiv = document.createElement('div');
Â  Â  Â  Â  loaderDiv.id = 'loader';
Â  Â  Â  Â  loaderDiv.className = 'loader';
Â  Â  Â  Â  chatLog.appendChild(loaderDiv);
Â  Â  Â  Â  chatLog.scrollTop = chatLog.scrollHeight;
Â  Â  Â  Â  voiceStatus.textContent = "Getting AI response...";


Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  const conversationHistory = getConversationHistory();
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // Add a system instruction to ground the model as an educational assistant AND request clean formatting
Â  Â  Â  Â  Â  Â  const systemInstruction = "You are LearnFlow AI, a helpful, friendly, and concise educational assistant. Please provide your response in plain text, without using any markdown formatting like **bolding** or *italics*. Respond to the user's query based on the conversation history.";

Â  Â  Â  Â  Â  Â  const payload = {
Â  Â  Â  Â  Â  Â  Â  Â  contents: [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  { role: 'user', parts: [{ text: systemInstruction }] }, // System instruction as the first turn
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ...conversationHistory, 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  { role: 'user', parts: [{ text: query }] } 
Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  };

Â  Â  Â  Â  Â  Â  const response = await fetch(apiUrl, {
Â  Â  Â  Â  Â  Â  Â  Â  method: "POST",
Â  Â  Â  Â  Â  Â  Â  Â  headers: { "Content-Type": "application/json" },
Â  Â  Â  Â  Â  Â  Â  Â  body: JSON.stringify(payload),
Â  Â  Â  Â  Â  Â  });
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  const data = await response.json();
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // 4. Remove Loader
Â  Â  Â  Â  Â  Â  const loader = document.getElementById('loader');
Â  Â  Â  Â  Â  Â  if (loader) { loader.remove(); }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // 5. Process and Display Response
Â  Â  Â  Â  Â  Â  const aiMsgDiv = document.createElement('div');
Â  Â  Â  Â  Â  Â  aiMsgDiv.className = "chat-message ai"; 
Â  Â  Â  Â  Â  Â  chatLog.appendChild(aiMsgDiv);
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  let fullText = "No response received. Please check the console (F12) for API errors.";
Â  Â  Â  Â  Â  Â  let isError = false;

Â  Â  Â  Â  Â  Â  if (data?.candidates?.[0]?.content?.parts?.length) {
Â  Â  Â  Â  Â  Â  Â  Â  fullText = data.candidates[0].content.parts.map(p => p.text).join("\n\n");
Â  Â  Â  Â  Â  Â  } else if (data.error) {
Â  Â  Â  Â  Â  Â  Â  Â  Â fullText = `API Error: ${data.error.message || "An unknown API error occurred."}`;
Â  Â  Â  Â  Â  Â  Â  Â  Â isError = true;
Â  Â  Â  Â  Â  Â  } else if (data.promptFeedback?.blockReason) {
Â  Â  Â  Â  Â  Â  Â  Â  Â fullText = `Response blocked. Reason: ${data.promptFeedback.blockReason}`;
Â  Â  Â  Â  Â  Â  Â  Â  Â isError = true;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (isError) {
Â  Â  Â  Â  Â  Â  Â  Â  aiMsgDiv.classList.add('error');
Â  Â  Â  Â  Â  Â  Â  Â  aiMsgDiv.innerHTML = `<strong>Ai:</strong> <span class="text-xl inline-block mr-2">ğŸš«</span> ${cleanText(fullText)}`;
Â  Â  Â  Â  Â  Â  Â  Â  saveChatHistory();
Â  Â  Â  Â  Â  Â  Â  Â  chatLog.scrollTop = chatLog.scrollHeight;
Â  Â  Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Error during API call.";
Â  Â  Â  Â  Â  Â  Â  Â  speakText("I encountered an error. " + fullText); 
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  // typeWriter now calls cleanText and then speakText 
Â  Â  Â  Â  Â  Â  Â  Â  typeWriter(aiMsgDiv, fullText); 
Â  Â  Â  Â  Â  Â  Â  Â  responseCount++;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  } catch (error) {
Â  Â  Â  Â  Â  Â  console.error("Fetch/Network Error:", error);
Â  Â  Â  Â  Â  Â  const loader = document.getElementById('loader');
Â  Â  Â  Â  Â  Â  if (loader) { loader.remove(); }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  const errorMsgDiv = document.createElement('div');
Â  Â  Â  Â  Â  Â  errorMsgDiv.className = "chat-message error"; 
Â  Â  Â  Â  Â  Â  const errorText = "Network Error. Could not reach the server.";
Â  Â  Â  Â  Â  Â  errorMsgDiv.innerHTML = `<strong>Ai:</strong> <span class="text-xl inline-block mr-2">ğŸš¨</span> ${errorText}`;
Â  Â  Â  Â  Â  Â  chatLog.appendChild(errorMsgDiv);
Â  Â  Â  Â  Â  Â  saveChatHistory();
Â  Â  Â  Â  Â  Â  chatLog.scrollTop = chatLog.scrollHeight;
Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Network Error.";
Â  Â  Â  Â  Â  Â  speakText("I encountered a network error.");
Â  Â  Â  Â  }
Â  Â  }
Â  Â  
Â  Â  // Function to extract conversation history in API format (updated to use cleanText)
Â  Â  function getConversationHistory() {
Â  Â  Â  Â  const history = [];
Â  Â  Â  Â  const children = Array.from(chatLog.children);
Â  Â  Â  Â  
Â  Â  Â  Â  // Start from the second message to skip the initial welcome message
Â  Â  Â  Â  for (let i = 1; i < children.length; i++) {
Â  Â  Â  Â  Â  Â  const child = children[i];
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // Skip non-message elements, error messages, and loaders
Â  Â  Â  Â  Â  Â  if (child.classList.contains('error') || child.id === 'loader' || child.id === 'summaryLoader') {
Â  Â  Â  Â  Â  Â  Â  Â  continue;
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  if (child.classList.contains('user')) {
Â  Â  Â  Â  Â  Â  Â  Â  const text = extractText(child, 'You:');
Â  Â  Â  Â  Â  Â  Â  Â  if (text) { history.push({ role: 'user', parts: [{ text: text }] }); }
Â  Â  Â  Â  Â  Â  } else if (child.classList.contains('ai')) {
Â  Â  Â  Â  Â  Â  Â  Â  // Remove all possible AI prefixes
Â  Â  Â  Â  Â  Â  Â  Â  let text = extractText(child, 'Ai:'); // Use extractText for robust prefix removal
Â  Â  Â  Â  Â  Â  Â  Â  // Clean the text before pushing to history for a cleaner context
Â  Â  Â  Â  Â  Â  Â  Â  text = cleanText(text); 
Â  Â  Â  Â  Â  Â  Â  Â  if (text) { history.push({ role: 'model', parts: [{ text: text }] }); }
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }
Â  Â  Â  Â  return history;
Â  Â  }

Â  Â  // Function to clear the chat history and the chat log display
Â  Â  function clearChat() {
Â  Â  Â  Â  if (!confirm("Are you sure you want to clear the entire chat history? This cannot be undone.")) {
Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  }
Â  Â  Â  Â  stopSpeaking(); 
Â  Â  Â  Â  chatLog.innerHTML = '';
Â  Â  Â  Â  localStorage.removeItem(chatHistoryKey);
Â  Â  Â  Â  responseCount = 0;
Â  Â  Â  Â  localStorage.setItem(responseCountKey, '0');
Â  Â  Â  Â  
Â  Â  Â  Â  // Re-add the welcome message
Â  Â  Â  Â  chatLog.innerHTML = `
Â  Â  Â  Â  Â  Â  <div class="chat-message ai">
Â  Â  Â  Â  Â  Â  Â  Â  <strong>Ai:</strong> 
Â  Â  Â  Â  Â  Â  Â  Â  <span class="text-gray-400">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Hello, {{ user.username }}! 
Â  Â  Â  Â  Â  Â  Â  Â  </span>
Â  Â  Â  Â  Â  Â  </div>`;
Â  Â  Â  Â  voiceStatus.textContent = "Chat cleared! Tap the microphone or type to speak...";
Â  Â  }

Â  Â  function exportChat() {
Â  Â  Â  Â  stopSpeaking(); 
Â  Â  Â  Â  // Use innerText to get only visible text content and clean it further
Â  Â  Â  Â  const plainText = `LearnFlow AI Chat Transcript for {{ user.username }}:\n\n${cleanText(chatLog.innerText.replace("Ai:", "\nAi:").replace("You:", "\n\nYou:").replace("Hello, {{ user.username }}!", "").trim())}`; 
Â  Â  Â  Â  const blob = new Blob([plainText], { type: 'text/plain;charset=utf-8' });
Â  Â  Â  Â  const link = document.createElement('a');
Â  Â  Â  Â  link.href = URL.createObjectURL(blob);
Â  Â  Â  Â  link.download = 'LearnFlow_Chat_Transcript.txt'; 
Â  Â  Â  Â  link.click();
Â  Â  Â  Â  
Â  Â  Â  Â  // Provide user feedback
Â  Â  Â  Â  voiceStatus.textContent = "Chat exported successfully!";
Â  Â  Â  Â  setTimeout(() => {
Â  Â  Â  Â  Â  Â  if (!isSpeaking) {
Â  Â  Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Tap the microphone to speak...";
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  }, 3000);
Â  Â  }
Â  Â  
Â  Â  // Summarize function - Calls speakText on completion (updated to use cleanText)
Â  Â  async function summarizeChat() {
Â  Â  Â  Â  stopSpeaking(); 
Â  Â  Â  Â  
Â  Â  Â  Â  const conversationHistory = getConversationHistory();
Â  Â  Â  Â  
Â  Â  Â  Â  if (conversationHistory.length === 0) {
Â  Â  Â  Â  Â  Â  const warningMsgDiv = document.createElement('div');
Â  Â  Â  Â  Â  Â  const noSummaryText = "No conversation to summarize. Start chatting!";
Â  Â  Â  Â  Â  Â  warningMsgDiv.className = "chat-message error";
Â  Â  Â  Â  Â  Â  // Use cleanText on display here just in case
Â  Â  Â  Â  Â  Â  warningMsgDiv.innerHTML = `<strong>Ai (Summary):</strong> <span class="text-xl inline-block mr-2">âš ï¸</span> ${cleanText(noSummaryText)}`; 
Â  Â  Â  Â  Â  Â  chatLog.appendChild(warningMsgDiv);
Â  Â  Â  Â  Â  Â  chatLog.scrollTop = chatLog.scrollHeight;
Â  Â  Â  Â  Â  Â  speakText(noSummaryText); 
Â  Â  Â  Â  Â  Â  return;
Â  Â  Â  Â  }

Â  Â  Â  Â  const loaderDiv = document.createElement('div');
Â  Â  Â  Â  loaderDiv.id = 'summaryLoader';
Â  Â  Â  Â  loaderDiv.className = 'loader';
Â  Â  Â  Â  chatLog.appendChild(loaderDiv);
Â  Â  Â  Â  chatLog.scrollTop = chatLog.scrollHeight;
Â  Â  Â  Â  voiceStatus.textContent = "Generating summary...";

Â  Â  Â  Â  // Added instruction to prompt to use plain text
Â  Â  Â  Â  const summaryPrompt = "Please provide a concise, numbered summary of the previous conversation in plain text, without using markdown like **bolding** or *italics*. Focus on the main topics and conclusions. Address the user directly as 'you'.";

Â  Â  Â  Â  // Create a new payload that includes the history AND the final summary prompt
Â  Â  Â  Â  const payload = {
Â  Â  Â  Â  Â  Â  contents: [
Â  Â  Â  Â  Â  Â  Â  Â  ...conversationHistory, 
Â  Â  Â  Â  Â  Â  Â  Â  { role: 'user', parts: [{ text: summaryPrompt }] } 
Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  };

Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  const response = await fetch(apiUrl, {
Â  Â  Â  Â  Â  Â  Â  Â  method: "POST",
Â  Â  Â  Â  Â  Â  Â  Â  headers: { "Content-Type": "application/json" },
Â  Â  Â  Â  Â  Â  Â  Â  body: JSON.stringify(payload),
Â  Â  Â  Â  Â  Â  });

Â  Â  Â  Â  Â  Â  const data = await response.json();

Â  Â  Â  Â  Â  Â  const loader = document.getElementById('summaryLoader');
Â  Â  Â  Â  Â  Â  if (loader) { loader.remove(); }

Â  Â  Â  Â  Â  Â  const aiMsgDiv = document.createElement('div');
Â  Â  Â  Â  Â  Â  aiMsgDiv.className = "chat-message ai";
Â  Â  Â  Â  Â  Â  chatLog.appendChild(aiMsgDiv);

Â  Â  Â  Â  Â  Â  let fullText = data.candidates?.[0]?.content?.parts?.[0]?.text || "No summary available. Check console for API errors.";
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  // Process and display the summary
Â  Â  Â  Â  Â  Â  typeWriter(aiMsgDiv, fullText); 
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  } catch (error) {
Â  Â  Â  Â  Â  Â  console.error("Summary Fetch/Network Error:", error);
Â  Â  Â  Â  Â  Â  const loader = document.getElementById('summaryLoader');
Â  Â  Â  Â  Â  Â  if (loader) { loader.remove(); }
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  const errorMsgDiv = document.createElement('div');
Â  Â  Â  Â  Â  Â  errorMsgDiv.className = "chat-message error"; 
Â  Â  Â  Â  Â  Â  const errorText = "Network Error. Could not generate summary.";
Â  Â  Â  Â  Â  Â  errorMsgDiv.innerHTML = `<strong>Ai (Summary):</strong> <span class="text-xl inline-block mr-2">ğŸš¨</span> ${errorText}`;
Â  Â  Â  Â  Â  Â  chatLog.appendChild(errorMsgDiv);
Â  Â  Â  Â  Â  Â  chatLog.scrollTop = chatLog.scrollHeight;
Â  Â  Â  Â  Â  Â  voiceStatus.textContent = "Summary Error.";
Â  Â  Â  Â  Â  Â  speakText("I encountered an error generating the summary.");
Â  Â  Â  Â  }
Â  Â  }
</script>
{% endblock %}