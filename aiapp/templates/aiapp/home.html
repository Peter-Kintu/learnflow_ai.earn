{% extends "base.html" %}

{% block title %}Home - LearnFlow AI{% endblock %}

{% block content %}
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&display=swap" rel="stylesheet">
<style>
   body {
      background: linear-gradient(135deg, #101725, #0a0e16);
      font-family: 'Inter', sans-serif;
      color: #e5e7eb;
      margin: 0;
   }

  .chat-container-card {
    max-width: 100%;
    width: clamp(300px, 90%, 1200px);
    margin: 2rem auto;
    padding: 1.5rem;
    background-color: #1f2937;
    border-radius: 1.5rem;
    box-shadow: 0 12px 40px rgba(0, 0, 0, 0.6);
    border: 1px solid #374151;
    overflow: hidden;
    transition: transform 0.4s ease, box-shadow 0.4s ease;
}

.chat-container-card:hover {
    transform: translateY(-4px);
    box-shadow: 0 16px 50px rgba(0, 0, 0, 0.7);
}


/* Header styling: Glassmorphism Effect */
.chat-header {
    /* Background must be slightly transparent with a blur */
    background: rgba(255, 255, 255, 0.1); 
    /* The key to glassmorphism */
    backdrop-filter: blur(10px); 
    -webkit-backdrop-filter: blur(10px); /* For Safari support */
    
    padding: 2.5rem 1.5rem; 
    border-radius: 12px; /* Rounded corners */
    border: 1px solid rgba(255, 255, 255, 0.18); /* Light border */
    box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.37); /* Stronger, transparent shadow */
    text-align: center;
}

.chat-header h1 {
    font-size: 3rem;
    font-weight: 700;
    /* Text color for glassmorphism often has a slight shadow or transparency */
    color: #ffffff; 
    text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.5); 
    letter-spacing: -0.04em;
    line-height: 1.1;
}

.chat-header p {
    font-size: 1.125rem;
    color: #f3f4f6; /* Very light color */
    margin-top: 0.5rem;
    max-width: 32rem;
    margin-left: auto;
    margin-right: auto;
}

/* Main chat area layout */
.chat-area {
    display: flex;
    flex-direction: column; /* Stacks on small screens */
    padding: 0; 
    gap: 0;
    /* On mobile, allow the chat area to use most of the screen */
    min-height: calc(100vh - 5rem); 
    max-height: 100vh;
}

/* Chat log container - Message feed */
#chatLog {
    flex-grow: 1;
    overflow-y: auto;
    padding: 1.5rem; 
    background-color: #0f172a; /* Very dark background for log */
    border: none;
    border-radius: 0;
    transition: background-color 0.3s ease-in-out;
    /* Removed min/max height properties to rely on flex-grow */
}

/* Message styling */
.chat-message {
    display: flex;
    align-items: flex-start;
    margin-bottom: 1rem;
    padding: 0.75rem 1rem;
    /* More distinct, modern rounded corners */
    border-radius: 1.25rem 0.5rem 1.25rem 0.5rem; 
    white-space: pre-wrap;
    word-wrap: break-word;
    max-width: 85%; /* Reduced max-width for better appearance */
    line-height: 1.5;
    font-size: 1rem;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2); /* Subtle shadow for depth */
}

.chat-message strong { font-weight: 700; margin-right: 0.5rem; min-width: fit-content; }

/* User message: brighter blue, distinct corner shape */
.chat-message.user { 
    justify-content: flex-end; 
    align-self: flex-end; 
    background-color: #6366f1; /* Brighter, more primary color */
    color: #ffffff; 
    border-radius: 1.25rem 0.5rem 0.5rem 1.25rem; /* Pointed top right */
}

/* AI message: darker background, distinct corner shape, slight border */
.chat-message.ai { 
    justify-content: flex-start; 
    align-self: flex-start; 
    background-color: #1f2937; 
    color: #e5e7eb; 
    border-radius: 0.5rem 1.25rem 1.25rem 0.5rem; /* Pointed top left */
    border: 1px solid #334155; 
}

.chat-message.error { background-color: #b91c1c; color: #ffffff; border: 1px solid #dc2626; }

/* Input and button area (Mobile - bottom dock) */
.chat-input-area {
    display: flex;
    flex-direction: column;
    gap: 1rem;
    padding: 1.5rem;
    border-top: 1px solid #374151;
    background-color: #1a2434; /* Slightly lighter dark color for contrast */
}

/* Combined Text and Voice Input Container */
.combined-input-container {
    display: flex;
    gap: 0.75rem;
    align-items: center;
    width: 100%;
}

/* Text Input Styling */
#chatInput {
    flex-grow: 1;
    padding: 0.75rem 1.25rem;
    border-radius: 1rem; /* Softened corners */
    background-color: #111827; /* Very dark input field */
    color: #e5e7eb;
    border: 1px solid #334155; /* Refined border color */
    transition: border-color 0.3s, box-shadow 0.3s;
    outline: none;
    font-size: 1rem;
    display: block !important; 
}
#chatInput:focus { 
    border-color: #818cf8; 
    box-shadow: 0 0 0 2px rgba(99, 102, 241, 0.5); /* Focus ring */
}

/* Send Button Styling */
.action-button.send {
    display: flex !important; 
    align-items: center;
    justify-content: center;
    padding: 0.75rem; /* Square padding */
    border-radius: 1rem; /* Matched input field radius */
    background-color: #6366f1; /* Matched user message color */
    color: #fff;
    font-weight: 600;
    border: none;
    cursor: pointer;
    transition: background-color 0.3s, transform 0.1s;
    flex-shrink: 0;
    width: 3.5rem; 
    height: 3.5rem;
}
.action-button.send:hover { background-color: #4f46e5; transform: translateY(-1px); }


/* Voice Input Styling (Retained for visual consistency) */
.voice-input-container {
    display: flex;
    gap: 1rem;
    align-items: center;
    width: 100%;
    padding: 0.5rem 0; 
}

#recordButton {
    /* ... (mostly kept the same, added shadow) ... */
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    /* ... */
}
/* ... (recordButton hover, recording, disabled, and pulse are kept) ... */

#voiceStatus {
    flex-grow: 1;
    color: #94a3b8; /* Slightly lighter status text */
    font-style: italic;
    padding: 0.5rem 0;
}

/* Button Group Styling (Mobile - horizontal wrap) */
.button-group {
    display: flex;
    flex-wrap: wrap;
    gap: 0.75rem;
    justify-content: center;
    padding-top: 0.5rem;
}

.action-button {
    flex: 1 1 150px; 
    padding: 0.75rem 1.25rem; /* Standardized button padding */
    border-radius: 0.75rem; /* Slightly softer radius for utility buttons */
    font-weight: 600;
    text-align: center;
    transition: all 0.3s ease-in-out;
    box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
    cursor: pointer;
    border: none;
}

/* NEW: Stop Speaking Button (kept original colors) */
.action-button.stop-speak { 
    background-color: #f59e0b; 
    color: #1f2937; 
    display: none; 
    order: -1; 
}
.action-button.stop-speak:hover { background-color: #d97706; transform: translateY(-2px); }

/* Other buttons (kept original colors, standardized hover effects) */
.action-button.summarize { background-color: #10b981; color: #fff; }
.action-button.summarize:hover { background-color: #059669; transform: translateY(-2px); }

.action-button.export { background-color: #3b82f6; color: #fff; }
.action-button.export:hover { background-color: #2563eb; transform: translateY(-2px); }

.action-button.clear { background-color: #ef4444; color: #fff; }
.action-button.clear:hover { background-color: #dc2626; transform: translateY(-2px); }

/* Responsive adjustments for large screens (md: 768px and up) */
@media (min-width: 768px) {
    /* Assuming a parent container of chat-container-card */
    .chat-container-card { max-width: 90%; height: 90vh; } 
    .chat-area { 
        flex-direction: row; 
        min-height: 100%; /* Fill the height of the container card */
    }
    
    /* Log on the left (65%) */
    #chatLog { 
        width: 65%; 
        min-height: 100%; 
        max-height: 100%; 
        border-radius: 0 0 0 1.5rem; 
        padding: 2rem; /* Increased padding on desktop */
        background-color: #0f172a; 
    }
    
    /* Utilities/Input on the right (35%) */
    .chat-input-area { 
        width: 35%; 
        border-top: none; 
        border-left: 1px solid #334155; /* Subtle border change */
        border-radius: 0 0 1.5rem 0; 
        flex-direction: column; 
        justify-content: flex-start;
        background-color: #111827; /* Slightly darker than log for contrast */
        padding: 2rem;
    }
    
    /* Button group becomes a vertical list of utilities */
    .button-group { 
        flex-direction: column; 
        gap: 1rem; 
        width: 100%;
        padding-top: 1rem;
    }
    .action-button { 
        flex: none; 
        width: 100%; 
        height: auto;
    }
    .action-button.stop-speak { flex: none; width: 100%; }
    
    /* Combined text/mic input remains horizontal */
    .combined-input-container {
        flex-direction: row; 
        height: 3.5rem; 
    }
    .action-button.send {
        width: 3.5rem; /* Force square */
        height: 3.5rem;
        padding: 0; 
        border-radius: 1rem;
    }
}

/* Loader styling (kept the same) */
.loader { width: 32px; height: 32px; border: 4px solid #4f46e5; border-top-color: transparent; border-radius: 50%; animation: spin 1s linear infinite; margin: 1.5rem auto; }
@keyframes spin { to { transform: rotate(360deg); } }

</style>

<div class="chat-container-card">
    <div class="chat-header">
        <h1 class="text-4xl sm:text-5xl font-extrabold text-white tracking-tight">
            Welcome, {{ user.username }} <span class="wave-emoji inline-block">👋</span>
        </h1>
        <p class="text-base sm:text-lg text-gray-400 font-light">
            You’ve joined LearnFlow AI, your powerful educational partner. 
        </p>
    </div>

    <div class="chat-area">
        <div id="chatLog" class="overflow-y-auto">
            </div>

        <div class="chat-input-area">
            <h2 class="text-2xl font-semibold text-indigo-400 flex items-center gap-2">
                <svg class="w-7 h-7 text-indigo-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"
                    xmlns="http://www.w3.org/2000/svg">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
                        d="M8 12h.01M12 12h.01M16 12h.01M21 12c0 4.418-4.03 8-9 8a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.549A9.863 9.863 0 0112 10a9.863 9.863 0 01-4.255-.949L3 20l1.395-3.549A9.863 9.863 0 0112 4c4.97 0 9 3.582 9 8z" />
                </svg>
                Ask LearnFlow AI 
            </h2>
            
                        <div class="combined-input-container">
                <input type="text" id="chatInput" placeholder="Type your question..." onkeydown="handleKey(event)">
                <button onclick="sendChat()" class="action-button send" id="sendChatButton">
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M13 10V3L4 14h7v7l9-11h-7z" />
                    </svg>
                </button> 
            </div>
            
                        <div class="voice-input-container">
                <button id="recordButton" onclick="toggleRecording()" title="Start Recording">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor">
                        <path d="M12 14c1.66 0 2.99-1.34 2.99-3L15 5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm5.3-3c0 3.9-3.4 7-7.3 7s-7.3-3.1-7.3-7H4c0 4.3 3.3 7.8 7.5 8.3v3.7h1v-3.7c4.2-.5 7.5-4 7.5-8.3h-2.7z"/>
                    </svg>
                </button>
                <div id="voiceStatus">Initializing voice service...</div>
            </div>
            
            <div class="button-group">
                <button onclick="stopSpeaking()" class="action-button stop-speak" id="stopSpeakingButton">
                    <span class="text-xl">🔇</span> Stop Speaking
                </button>
                
                <button onclick="summarizeChat()" class="action-button summarize">Summarize Chat</button>
                <button onclick="exportChat()" class="action-button export">Export Chat</button>
                <button onclick="clearChat()" class="action-button clear">Clear Chat</button>
            </div>
        </div>
    </div>
</div>

<script>
    // Constants and Global Variables
    const chatLog = document.getElementById('chatLog');
    const stopSpeakingButton = document.getElementById('stopSpeakingButton');
    const recordButton = document.getElementById('recordButton');
    const voiceStatus = document.getElementById('voiceStatus');
    const chatInput = document.getElementById('chatInput'); // New reference

    const responseLimit = 3; // Set your limit
    const username = "{{ user.username }}";
    const chatHistoryKey = `chatHistory-${username}`;
    const responseCountKey = `responseCount-${username}`;
    let responseCount = localStorage.getItem(responseCountKey) ? parseInt(localStorage.getItem(responseCountKey)) : 0;
    
    // --- Speech Synthesis Variables (TTS) ---
    let voices = [];
    let isSpeaking = false; // Tracks if the AI is currently speaking
    
    // --- Speech Recognition Variables (STT) ---
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    let recognition = null;
    let isRecording = false; // Tracks if the microphone is actively listening

    // --- API Configuration ---
    // NOTE: REPLACE THIS PLACEHOLDER WITH YOUR ACTUAL GEMINI API KEY!
    const apiKey = "AIzaSyBo-nakWm_HBUBStldTAKzcAdvB4OU46HU"; 
    const modelName = 'gemini-2.5-flash'; 
    const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/${modelName}:generateContent?key=${apiKey}`;

    // Helper to extract a clean text message from a chat message div
    function extractText(child, prefix) {
        // Find the text content, and remove the prefix and any strong tags
        let text = child.textContent.trim();
        // More robust prefix removal for the history extraction
        if (text.startsWith(prefix)) {
            text = text.substring(prefix.length).trim();
        }
        // Ensure any strong tag content is removed if not done above
        if (child.querySelector('strong')) {
            text = text.replace(child.querySelector('strong').textContent, '').trim();
        }
        return text;
    }

    // ## TTS Functions (Text-to-Speech) ##
    
    function populateVoices() {
        voices = speechSynthesis.getVoices();
    }
    
    populateVoices();
    if (speechSynthesis.onvoiceschanged !== undefined) {
        speechSynthesis.onvoiceschanged = populateVoices;
    }

    function speakText(text) {
        if (!('speechSynthesis' in window)) {
            // Do not speak if not supported
            return;
        }

        stopSpeaking(); // Stop any current speech before starting a new one

        isSpeaking = true;
        stopSpeakingButton.style.display = 'block'; 

        const utterance = new SpeechSynthesisUtterance(text);
        
        // Attempt to find a preferred voice
        const preferredVoices = [
            "Google US English", "Microsoft Zira", "Daniel", "Samantha", "Ting-Ting"
        ];

        let selectedVoice = null;
        for (let name of preferredVoices) {
            selectedVoice = voices.find(voice => voice.name.includes(name));
            if (selectedVoice) break;
        }
        
        // Fallback to a generic English voice
        if (!selectedVoice) {
            selectedVoice = voices.find(voice => voice.lang.includes('en'));
        }
        
        if (selectedVoice) {
            utterance.voice = selectedVoice;
        }
        
        utterance.rate = 1.0; 
        utterance.pitch = 1.0; 

        utterance.onend = () => {
            isSpeaking = false;
            stopSpeakingButton.style.display = 'none'; 
            // Ready for next input after AI finishes speaking
            if (!isRecording) {
                voiceStatus.textContent = "Tap the microphone to speak...";
            }
        };
        
        utterance.onerror = (event) => {
            console.error('Speech synthesis error:', event);
            isSpeaking = false;
            stopSpeakingButton.style.display = 'none';
             if (!isRecording) {
                voiceStatus.textContent = "Tap the microphone to speak...";
            }
        };

        speechSynthesis.speak(utterance);
    }
    
    function stopSpeaking() {
        if ('speechSynthesis' in window && speechSynthesis.speaking) {
            speechSynthesis.cancel();
            isSpeaking = false;
            stopSpeakingButton.style.display = 'none';
            // Update status only if not currently recording
            if (!isRecording) {
                 voiceStatus.textContent = "Tap the microphone to speak...";
            }
        }
    }

    // ## STT Functions (Speech-to-Text) ##

    function setupRecognition() {
        if (!SpeechRecognition) {
            voiceStatus.textContent = "Voice input not supported. Use Chrome or Edge.";
            recordButton.disabled = true;
            return;
        }
        
        recognition = new SpeechRecognition();
        recognition.continuous = false; // Get one result per recording
        recognition.interimResults = false;
        recognition.lang = 'en-US';

        recognition.onstart = () => {
            isRecording = true;
            recordButton.classList.add('recording');
            voiceStatus.textContent = "Listening... Speak clearly now.";
            stopSpeaking(); // Stop AI from talking when user starts speaking
        };

        recognition.onresult = (event) => {
            const last = event.results.length - 1;
            const transcript = event.results[last][0].transcript;
            console.log("Transcript:", transcript);
            // Immediately process the transcription
            processVoiceQuery(transcript);
        };

        recognition.onerror = (event) => {
            console.error('Speech recognition error:', event.error);
            // Stop recording state
            isRecording = false; 
            recordButton.classList.remove('recording');
            
            // Provide specific user feedback
            if (event.error === 'not-allowed') {
                voiceStatus.textContent = "Permission denied. Please enable microphone access.";
            } else if (event.error === 'no-speech') {
                voiceStatus.textContent = "No speech detected. Tap the microphone to try again.";
            } else if (event.error !== 'aborted') {
                voiceStatus.textContent = `Error: ${event.error}. Tap the microphone to try again.`;
            } else {
                // 'aborted' can happen when recognition.stop() is called manually
                 voiceStatus.textContent = "Tap the microphone to speak...";
            }
        };
        
        recognition.onend = () => {
             // Only reset UI state if a full query process is not ongoing
             if (isRecording) {
                 recordButton.classList.remove('recording');
                 isRecording = false;
                 // Status will be updated by speakText.onend or the error handler
             }
        };
    }
    
    // Initialize recognition on load
    setupRecognition();

    function toggleRecording() {
        if (!recognition) return; 

        if (isRecording) {
            // Stop recording if the user taps the button again
            recognition.stop();
        } else if (isSpeaking) {
             // If AI is speaking, interrupt it
             stopSpeaking();
             voiceStatus.textContent = "Interrupted. Tap to speak...";
        } else {
            // Start recording
            try {
                recognition.start();
            } catch (e) {
                // Catch error if recognition.start() is called when already active (shouldn't happen with state check)
                 if (e.name !== 'InvalidStateError') {
                     console.error("Recording error:", e);
                     voiceStatus.textContent = "Error starting mic. Check console/permissions.";
                 }
            }
        }
    }
    
    // Function to handle the transcribed query
    function processVoiceQuery(query) {
        if (query.trim()) {
            voiceStatus.textContent = "Sending question to AI...";
            sendGeminiQuery(query.trim());
        } else {
            voiceStatus.textContent = "Empty recording. Tap the microphone to speak...";
        }
    }


    // ## Core Chat/API Functions ##

    // Handles Enter key press on the text input
    function handleKey(event) {
        if (event.key === 'Enter') {
            sendChat();
        }
    }

    // Function to handle text input and trigger the query
    function sendChat() {
        const query = chatInput.value.trim();
        if (query) {
            if (isRecording) {
                recognition.stop(); // Stop voice input if text is sent
            }
            chatInput.value = ''; // Clear input field
            sendGeminiQuery(query);
        }
    }

    // Load chat history from localStorage on page load
    document.addEventListener('DOMContentLoaded', () => {
        const storedChat = localStorage.getItem(chatHistoryKey);
        stopSpeakingButton.style.display = 'none';

        if (storedChat) {
            chatLog.innerHTML = storedChat;
        }
        
        // Ensure the initial welcome message is present
        if (!chatLog.innerHTML.includes("Hello, {{ user.username }}!")) {
             chatLog.innerHTML = `
                 <div class="chat-message ai">
                     <strong>Ai:</strong> 
                     <span class="text-gray-400">
                         Hello, {{ user.username }}! 
                     </span>
                 </div>` + chatLog.innerHTML;
        } 
        
        chatLog.scrollTop = chatLog.scrollHeight;
        voiceStatus.textContent = recognition ? "Tap the microphone to speak..." : "Voice service unavailable.";
    });

    function saveChatHistory() {
        localStorage.setItem(chatHistoryKey, chatLog.innerHTML);
        localStorage.setItem(responseCountKey, responseCount);
    }
    
    // Function to remove markdown formatting (like ** for bolding) from text
    function cleanText(text) {
        // Remove double asterisks (**) for bolding, asterisks (*) for italics, and new lines
        return text.replace(/\*\*/g, '').replace(/\*/g, '').replace(/\n/g, ' ').trim();
    }

    // Typing animation function - Calls speakText on completion
    function typeWriter(element, text, speed = 15) { 
        // Apply cleaning right here before display
        const cleanedText = cleanText(text); 
        
        let i = 0;
        // Use an empty string for the AI prefix as the strong tag already exists
        element.innerHTML = `<strong>Ai:</strong> `; 
        const contentSpan = document.createElement('span');
        element.appendChild(contentSpan);

        function type() {
            // Check if the speech was cancelled manually
            if (!isSpeaking && i > 0) return; 

            if (i < cleanedText.length) {
                contentSpan.textContent += cleanedText.charAt(i); 
                i++;
                setTimeout(type, speed);
            } else {
                saveChatHistory();
                speakText(cleanedText); // <-- Speak the cleaned text after typing
            }
            chatLog.scrollTop = chatLog.scrollHeight;
        }
        type();
    }
    
    // Main function to send the query to Gemini and handle the response
    async function sendGeminiQuery(query) {
        stopSpeaking(); // Ensure no lingering speech
        
        // 1. Display user message
        const userMsgDiv = document.createElement('div');
        userMsgDiv.className = "chat-message user";
        userMsgDiv.innerHTML = `<strong>You:</strong> ${query}`;
        chatLog.appendChild(userMsgDiv);
        chatLog.scrollTop = chatLog.scrollHeight;
        saveChatHistory();
        
        // 2. Rate Limit Check
        if (responseCount >= responseLimit) {
            const upgradeMsg = `You've reached your free chat limit of ${responseLimit} questions! Please upgrade for unlimited access.`;
            const aiMsgDiv = document.createElement('div');
            aiMsgDiv.className = "chat-message error"; 
            aiMsgDiv.innerHTML = `<strong>Ai:</strong> <span class="text-xl inline-block mr-2">🔒</span> ${upgradeMsg}`;
            chatLog.appendChild(aiMsgDiv);
            saveChatHistory();
            chatLog.scrollTop = chatLog.scrollHeight;
            voiceStatus.textContent = "Free limit reached. Clear chat or upgrade.";
            speakText(upgradeMsg); // Speak the error message
            return;
        }

        // 3. Display Loader
        const loaderDiv = document.createElement('div');
        loaderDiv.id = 'loader';
        loaderDiv.className = 'loader';
        chatLog.appendChild(loaderDiv);
        chatLog.scrollTop = chatLog.scrollHeight;
        voiceStatus.textContent = "Getting AI response...";


        try {
            const conversationHistory = getConversationHistory();
            
            // Add a system instruction to ground the model as an educational assistant AND request clean formatting
            const systemInstruction = "You are LearnFlow AI, a helpful, friendly, and concise educational assistant. Please provide your response in plain text, without using any markdown formatting like **bolding** or *italics*. Respond to the user's query based on the conversation history.";

            const payload = {
                contents: [
                    { role: 'user', parts: [{ text: systemInstruction }] }, // System instruction as the first turn
                    ...conversationHistory, 
                    { role: 'user', parts: [{ text: query }] } 
                ]
            };

            const response = await fetch(apiUrl, {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify(payload),
            });
            
            const data = await response.json();
            
            // 4. Remove Loader
            const loader = document.getElementById('loader');
            if (loader) { loader.remove(); }
            
            // 5. Process and Display Response
            const aiMsgDiv = document.createElement('div');
            aiMsgDiv.className = "chat-message ai"; 
            chatLog.appendChild(aiMsgDiv);
            
            let fullText = "No response received. Please check the console (F12) for API errors.";
            let isError = false;

            if (data?.candidates?.[0]?.content?.parts?.length) {
                fullText = data.candidates[0].content.parts.map(p => p.text).join("\n\n");
            } else if (data.error) {
                 fullText = `API Error: ${data.error.message || "An unknown API error occurred."}`;
                 isError = true;
            } else if (data.promptFeedback?.blockReason) {
                 fullText = `Response blocked. Reason: ${data.promptFeedback.blockReason}`;
                 isError = true;
            }

            if (isError) {
                aiMsgDiv.classList.add('error');
                aiMsgDiv.innerHTML = `<strong>Ai:</strong> <span class="text-xl inline-block mr-2">🚫</span> ${cleanText(fullText)}`;
                saveChatHistory();
                chatLog.scrollTop = chatLog.scrollHeight;
                voiceStatus.textContent = "Error during API call.";
                speakText("I encountered an error. " + fullText); 
            } else {
                // typeWriter now calls cleanText and then speakText 
                typeWriter(aiMsgDiv, fullText); 
                responseCount++;
            }
            
        } catch (error) {
            console.error("Fetch/Network Error:", error);
            const loader = document.getElementById('loader');
            if (loader) { loader.remove(); }
            
            const errorMsgDiv = document.createElement('div');
            errorMsgDiv.className = "chat-message error"; 
            const errorText = "Network Error. Could not reach the server.";
            errorMsgDiv.innerHTML = `<strong>Ai:</strong> <span class="text-xl inline-block mr-2">🚨</span> ${errorText}`;
            chatLog.appendChild(errorMsgDiv);
            saveChatHistory();
            chatLog.scrollTop = chatLog.scrollHeight;
            voiceStatus.textContent = "Network Error.";
            speakText("I encountered a network error.");
        }
    }
    
    // Function to extract conversation history in API format (updated to use cleanText)
    function getConversationHistory() {
        const history = [];
        const children = Array.from(chatLog.children);
        
        // Start from the second message to skip the initial welcome message
        for (let i = 1; i < children.length; i++) {
            const child = children[i];
            
            // Skip non-message elements, error messages, and loaders
            if (child.classList.contains('error') || child.id === 'loader' || child.id === 'summaryLoader') {
                continue;
            }

            if (child.classList.contains('user')) {
                const text = extractText(child, 'You:');
                if (text) { history.push({ role: 'user', parts: [{ text: text }] }); }
            } else if (child.classList.contains('ai')) {
                // Remove all possible AI prefixes
                let text = extractText(child, 'Ai:'); // Use extractText for robust prefix removal
                // Clean the text before pushing to history for a cleaner context
                text = cleanText(text); 
                if (text) { history.push({ role: 'model', parts: [{ text: text }] }); }
            }
        }
        return history;
    }

    // Function to clear the chat history and the chat log display
    function clearChat() {
        if (!confirm("Are you sure you want to clear the entire chat history? This cannot be undone.")) {
            return;
        }
        stopSpeaking(); 
        chatLog.innerHTML = '';
        localStorage.removeItem(chatHistoryKey);
        responseCount = 0;
        localStorage.setItem(responseCountKey, '0');
        
        // Re-add the welcome message
        chatLog.innerHTML = `
            <div class="chat-message ai">
                <strong>Ai:</strong> 
                <span class="text-gray-400">
                    Hello, {{ user.username }}! 
                </span>
            </div>`;
        voiceStatus.textContent = "Chat cleared! Tap the microphone or type to speak...";
    }

    function exportChat() {
        stopSpeaking(); 
        // Use innerText to get only visible text content and clean it further
        const plainText = `LearnFlow AI Chat Transcript for {{ user.username }}:\n\n${cleanText(chatLog.innerText.replace("Ai:", "\nAi:").replace("You:", "\n\nYou:").replace("Hello, {{ user.username }}!", "").trim())}`; 
        const blob = new Blob([plainText], { type: 'text/plain;charset=utf-8' });
        const link = document.createElement('a');
        link.href = URL.createObjectURL(blob);
        link.download = 'LearnFlow_Chat_Transcript.txt'; 
        link.click();
        
        // Provide user feedback
        voiceStatus.textContent = "Chat exported successfully!";
        setTimeout(() => {
            if (!isSpeaking) {
                voiceStatus.textContent = "Tap the microphone to speak...";
            }
        }, 3000);
    }
    
    // Summarize function - Calls speakText on completion (updated to use cleanText)
    async function summarizeChat() {
        stopSpeaking(); 
        
        const conversationHistory = getConversationHistory();
        
        if (conversationHistory.length === 0) {
            const warningMsgDiv = document.createElement('div');
            const noSummaryText = "No conversation to summarize. Start chatting!";
            warningMsgDiv.className = "chat-message error";
            // Use cleanText on display here just in case
            warningMsgDiv.innerHTML = `<strong>Ai (Summary):</strong> <span class="text-xl inline-block mr-2">⚠️</span> ${cleanText(noSummaryText)}`; 
            chatLog.appendChild(warningMsgDiv);
            chatLog.scrollTop = chatLog.scrollHeight;
            speakText(noSummaryText); 
            return;
        }

        const loaderDiv = document.createElement('div');
        loaderDiv.id = 'summaryLoader';
        loaderDiv.className = 'loader';
        chatLog.appendChild(loaderDiv);
        chatLog.scrollTop = chatLog.scrollHeight;
        voiceStatus.textContent = "Generating summary...";

        // Added instruction to prompt to use plain text
        const summaryPrompt = "Please provide a concise, numbered summary of the previous conversation in plain text, without using markdown like **bolding** or *italics*. Focus on the main topics and conclusions. Address the user directly as 'you'.";

        // Create a new payload that includes the history AND the final summary prompt
        const payload = {
            contents: [
                ...conversationHistory, 
                { role: 'user', parts: [{ text: summaryPrompt }] } 
            ]
        };

        try {
            const response = await fetch(apiUrl, {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify(payload),
            });

            const data = await response.json();

            const loader = document.getElementById('summaryLoader');
            if (loader) { loader.remove(); }

            const aiMsgDiv = document.createElement('div');
            aiMsgDiv.className = "chat-message ai";
            chatLog.appendChild(aiMsgDiv);

            let fullText = data.candidates?.[0]?.content?.parts?.[0]?.text || "No summary available. Check console for API errors.";
            
            // Process and display the summary
            typeWriter(aiMsgDiv, fullText); 
            
        } catch (error) {
            console.error("Summary Fetch/Network Error:", error);
            const loader = document.getElementById('summaryLoader');
            if (loader) { loader.remove(); }
            
            const errorMsgDiv = document.createElement('div');
            errorMsgDiv.className = "chat-message error"; 
            const errorText = "Network Error. Could not generate summary.";
            errorMsgDiv.innerHTML = `<strong>Ai (Summary):</strong> <span class="text-xl inline-block mr-2">🚨</span> ${errorText}`;
            chatLog.appendChild(errorMsgDiv);
            chatLog.scrollTop = chatLog.scrollHeight;
            voiceStatus.textContent = "Summary Error.";
            speakText("I encountered an error generating the summary.");
        }
    }
</script>
{% endblock %}